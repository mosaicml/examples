{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a87034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af49f6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpu_num</th>\n",
       "      <th>parameters-icl_tasks</th>\n",
       "      <th>parameters-model</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>eval_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>piqa</td>\n",
       "      <td>125m</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-piqa-model-125m-...</td>\n",
       "      <td>718.886351</td>\n",
       "      <td>0.628945</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>piqa</td>\n",
       "      <td>1.3b</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-piqa-model-1-3b-...</td>\n",
       "      <td>1927.111743</td>\n",
       "      <td>0.707835</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>piqa</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-piqa-model-2-7b-...</td>\n",
       "      <td>3260.289173</td>\n",
       "      <td>0.731774</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>piqa</td>\n",
       "      <td>125m</td>\n",
       "      <td>gpt-eval-gpu-num-32-icl-tasks-piqa-model-125m-...</td>\n",
       "      <td>733.135527</td>\n",
       "      <td>0.628945</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>piqa</td>\n",
       "      <td>1.3b</td>\n",
       "      <td>gpt-eval-gpu-num-32-icl-tasks-piqa-model-1-3b-...</td>\n",
       "      <td>2025.282325</td>\n",
       "      <td>0.707835</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>8</td>\n",
       "      <td>lambada</td>\n",
       "      <td>1.3b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-lambada-model-1-3...</td>\n",
       "      <td>69.163373</td>\n",
       "      <td>0.571705</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>8</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...</td>\n",
       "      <td>117.466429</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>8</td>\n",
       "      <td>piqa</td>\n",
       "      <td>125m</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-piqa-model-125m-5523</td>\n",
       "      <td>123.490922</td>\n",
       "      <td>0.623217</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8</td>\n",
       "      <td>piqa</td>\n",
       "      <td>1.3b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-piqa-model-1-3b-3502</td>\n",
       "      <td>476.884176</td>\n",
       "      <td>0.709726</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8</td>\n",
       "      <td>piqa</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-piqa-model-2-7b-8871</td>\n",
       "      <td>813.257942</td>\n",
       "      <td>0.727551</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gpu_num parameters-icl_tasks parameters-model  \\\n",
       "0        64                 piqa             125m   \n",
       "1        64                 piqa             1.3b   \n",
       "2        64                 piqa             2.7b   \n",
       "3        32                 piqa             125m   \n",
       "4        32                 piqa             1.3b   \n",
       "..      ...                  ...              ...   \n",
       "61        8              lambada             1.3b   \n",
       "62        8              lambada             2.7b   \n",
       "63        8                 piqa             125m   \n",
       "64        8                 piqa             1.3b   \n",
       "65        8                 piqa             2.7b   \n",
       "\n",
       "                                             run_name     run_time  accuracy  \\\n",
       "0   gpt-eval-gpu-num-64-icl-tasks-piqa-model-125m-...   718.886351  0.628945   \n",
       "1   gpt-eval-gpu-num-64-icl-tasks-piqa-model-1-3b-...  1927.111743  0.707835   \n",
       "2   gpt-eval-gpu-num-64-icl-tasks-piqa-model-2-7b-...  3260.289173  0.731774   \n",
       "3   gpt-eval-gpu-num-32-icl-tasks-piqa-model-125m-...   733.135527  0.628945   \n",
       "4   gpt-eval-gpu-num-32-icl-tasks-piqa-model-1-3b-...  2025.282325  0.707835   \n",
       "..                                                ...          ...       ...   \n",
       "61  gpt-eval-gpu-num-8-icl-tasks-lambada-model-1-3...    69.163373  0.571705   \n",
       "62  gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...   117.466429  0.622093   \n",
       "63  gpt-eval-gpu-num-8-icl-tasks-piqa-model-125m-5523   123.490922  0.623217   \n",
       "64  gpt-eval-gpu-num-8-icl-tasks-piqa-model-1-3b-3502   476.884176  0.709726   \n",
       "65  gpt-eval-gpu-num-8-icl-tasks-piqa-model-2-7b-8871   813.257942  0.727551   \n",
       "\n",
       "   eval_method  \n",
       "0     eleuther  \n",
       "1     eleuther  \n",
       "2     eleuther  \n",
       "3     eleuther  \n",
       "4     eleuther  \n",
       "..         ...  \n",
       "61    composer  \n",
       "62    composer  \n",
       "63    composer  \n",
       "64    composer  \n",
       "65    composer  \n",
       "\n",
       "[91 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('eleuther_eval_jobs.tsv', 'r') as f:\n",
    "    df1 = pd.read_csv(f, sep='\\t', index_col=None)\n",
    "\n",
    "df1['eval_method'] = 'eleuther'\n",
    "with open('composer_eval_jobs.tsv', 'r') as f:\n",
    "    df2 = pd.read_csv(f, sep='\\t', index_col=None)\n",
    "\n",
    "df2['eval_method'] = 'composer'\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd436d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpu_num</th>\n",
       "      <th>parameters-icl_tasks</th>\n",
       "      <th>parameters-model</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>eval_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>lambada</td>\n",
       "      <td>1.3b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-lambada-model-1-3...</td>\n",
       "      <td>546.160601</td>\n",
       "      <td>0.571900</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>piqa</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-piqa-model-2-7b-0714</td>\n",
       "      <td>6493.076296</td>\n",
       "      <td>0.728205</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>piqa</td>\n",
       "      <td>1.3b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-piqa-model-1-3b-1154</td>\n",
       "      <td>3804.749575</td>\n",
       "      <td>0.707704</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>piqa</td>\n",
       "      <td>125m</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-piqa-model-125m-5866</td>\n",
       "      <td>979.931637</td>\n",
       "      <td>0.623196</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...</td>\n",
       "      <td>931.951627</td>\n",
       "      <td>0.622162</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>piqa</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-piqa-model-2-7b-...</td>\n",
       "      <td>3260.289173</td>\n",
       "      <td>0.731774</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>piqa</td>\n",
       "      <td>1.3b</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-piqa-model-1-3b-...</td>\n",
       "      <td>1927.111743</td>\n",
       "      <td>0.707835</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>lambada</td>\n",
       "      <td>125m</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-lambada-model-12...</td>\n",
       "      <td>1017.287463</td>\n",
       "      <td>0.373569</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>lambada</td>\n",
       "      <td>1.3b</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-lambada-model-1-...</td>\n",
       "      <td>2695.111596</td>\n",
       "      <td>0.572094</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>piqa</td>\n",
       "      <td>125m</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-piqa-model-125m-...</td>\n",
       "      <td>718.886351</td>\n",
       "      <td>0.628945</td>\n",
       "      <td>eleuther</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gpu_num parameters-icl_tasks parameters-model  \\\n",
       "25        1              lambada             1.3b   \n",
       "29        1                 piqa             2.7b   \n",
       "28        1                 piqa             1.3b   \n",
       "27        1                 piqa             125m   \n",
       "26        1              lambada             2.7b   \n",
       "..      ...                  ...              ...   \n",
       "2        64                 piqa             2.7b   \n",
       "1        64                 piqa             1.3b   \n",
       "12       64              lambada             125m   \n",
       "16       64              lambada             1.3b   \n",
       "0        64                 piqa             125m   \n",
       "\n",
       "                                             run_name     run_time  accuracy  \\\n",
       "25  gpt-eval-gpu-num-8-icl-tasks-lambada-model-1-3...   546.160601  0.571900   \n",
       "29  gpt-eval-gpu-num-8-icl-tasks-piqa-model-2-7b-0714  6493.076296  0.728205   \n",
       "28  gpt-eval-gpu-num-8-icl-tasks-piqa-model-1-3b-1154  3804.749575  0.707704   \n",
       "27  gpt-eval-gpu-num-8-icl-tasks-piqa-model-125m-5866   979.931637  0.623196   \n",
       "26  gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...   931.951627  0.622162   \n",
       "..                                                ...          ...       ...   \n",
       "2   gpt-eval-gpu-num-64-icl-tasks-piqa-model-2-7b-...  3260.289173  0.731774   \n",
       "1   gpt-eval-gpu-num-64-icl-tasks-piqa-model-1-3b-...  1927.111743  0.707835   \n",
       "12  gpt-eval-gpu-num-64-icl-tasks-lambada-model-12...  1017.287463  0.373569   \n",
       "16  gpt-eval-gpu-num-64-icl-tasks-lambada-model-1-...  2695.111596  0.572094   \n",
       "0   gpt-eval-gpu-num-64-icl-tasks-piqa-model-125m-...   718.886351  0.628945   \n",
       "\n",
       "   eval_method  \n",
       "25    composer  \n",
       "29    composer  \n",
       "28    composer  \n",
       "27    composer  \n",
       "26    composer  \n",
       "..         ...  \n",
       "2     eleuther  \n",
       "1     eleuther  \n",
       "12    eleuther  \n",
       "16    eleuther  \n",
       "0     eleuther  \n",
       "\n",
       "[76 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "graph_partition_cols = ['parameters-icl_tasks', 'parameters-model'] # diff values will be on diff graphs\n",
    "line_partition_cols = ['eval_method'] # diff values will be diff lines\n",
    "\n",
    "graph_partition_vals = {\n",
    "    k: set(df[k]) for k in graph_partition_cols\n",
    "}\n",
    "line_partition_vals = {\n",
    "    k: set(df[k]) for k in line_partition_cols\n",
    "}\n",
    "x_col = 'gpu_num'\n",
    "y_col = 'run_time'\n",
    "df.sort_values(by=['gpu_num'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08745546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_graphs(df, graph_partition_vals):\n",
    "    keys, vals = graph_partition_vals.keys(), graph_partition_vals.values()\n",
    "    \n",
    "    dataset_graph_partitions = []\n",
    "    for combo in itertools.product(*vals):\n",
    "        filter_string = \"\"\n",
    "        \n",
    "        df_part = {}\n",
    "        df_part['choices'] = {}\n",
    "        \n",
    "        for col_name, col_val in zip(keys, combo):\n",
    "            filter_string += f\"`{col_name}` == '{col_val}' and\"\n",
    "            df_part['choices'][col_name] = col_val\n",
    "            \n",
    "        filter_string = filter_string[:-4]\n",
    "        df_subset = df.query(filter_string)\n",
    "        df_part['df'] = df_subset\n",
    "        dataset_graph_partitions.append(df_part)\n",
    "    \n",
    "    return dataset_graph_partitions\n",
    "\n",
    "\n",
    "\n",
    "graph_partitions = partition_graphs(df, graph_partition_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d8cfa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_lines(df, line_partition_vals):\n",
    "    keys, vals = line_partition_vals.keys(), line_partition_vals.values()\n",
    "    dataset_line_partitions = []\n",
    "    for combo in itertools.product(*vals):\n",
    "        filter_string = \"\"\n",
    "        \n",
    "        df_part = {}\n",
    "        df_part['choices'] = {}\n",
    "        \n",
    "        for col_name, col_val in zip(keys, combo):\n",
    "            filter_string += f\"`{col_name}` == '{col_val}' and\"\n",
    "            df_part['choices'][col_name] = col_val\n",
    "            \n",
    "        filter_string = filter_string[:-4]\n",
    "        df_subset = df.query(filter_string)\n",
    "        df_part['df'] = df_subset\n",
    "        dataset_line_partitions.append(df_part)\n",
    "    return dataset_line_partitions \n",
    "\n",
    "def make_title(choices):\n",
    "    if 'eval_method' in choices:\n",
    "        return f\"{choices['eval_method']}-based eval, {choices['parameters-icl_tasks'].upper()}\"\n",
    "    elif 'parameters-model' in choices:\n",
    "        return f\"{choices['parameters-model']} parameter model, {choices['parameters-icl_tasks'].upper()}\"\n",
    "    else:\n",
    "        return None\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c24e2fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for idx, graph_info in enumerate(graph_partitions):\n",
    "    choices = graph_info['choices']\n",
    "    line_partitions = partition_lines(graph_info['df'], line_partition_vals)\n",
    "    legend = []\n",
    "    for line in line_partitions:\n",
    "        legend.append(', '.join(line['choices'].values()))\n",
    "        plt.plot(line['df'][x_col],line['df'][y_col])\n",
    "    \n",
    "    \n",
    "    plt.legend(legend)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    \n",
    "    plt.title(make_title(choices))\n",
    "    plt.xlabel('Number of GPUs')\n",
    "    plt.ylabel('Run time (seconds)')\n",
    "    plt.savefig(f\"fig{idx}.png\", )\n",
    "    plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4020f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpu_num</th>\n",
       "      <th>parameters-icl_tasks</th>\n",
       "      <th>parameters-model</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>eval_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...</td>\n",
       "      <td>931.951627</td>\n",
       "      <td>0.622162</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...</td>\n",
       "      <td>117.373195</td>\n",
       "      <td>0.623253</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>8</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...</td>\n",
       "      <td>117.466429</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>16</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-16-icl-tasks-lambada-model-2-...</td>\n",
       "      <td>59.242780</td>\n",
       "      <td>0.621904</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-16-icl-tasks-lambada-model-2-...</td>\n",
       "      <td>59.174347</td>\n",
       "      <td>0.623253</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>32</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-32-icl-tasks-lambada-model-2-...</td>\n",
       "      <td>30.257925</td>\n",
       "      <td>0.622106</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-32-icl-tasks-lambada-model-2-...</td>\n",
       "      <td>30.006946</td>\n",
       "      <td>0.623253</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-lambada-model-2-...</td>\n",
       "      <td>15.647013</td>\n",
       "      <td>0.622106</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>64</td>\n",
       "      <td>lambada</td>\n",
       "      <td>2.7b</td>\n",
       "      <td>gpt-eval-gpu-num-64-icl-tasks-lambada-model-2-...</td>\n",
       "      <td>15.661913</td>\n",
       "      <td>0.622106</td>\n",
       "      <td>composer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gpu_num parameters-icl_tasks parameters-model  \\\n",
       "26        1              lambada             2.7b   \n",
       "13        8              lambada             2.7b   \n",
       "62        8              lambada             2.7b   \n",
       "56       16              lambada             2.7b   \n",
       "9        16              lambada             2.7b   \n",
       "50       32              lambada             2.7b   \n",
       "5        32              lambada             2.7b   \n",
       "1        64              lambada             2.7b   \n",
       "44       64              lambada             2.7b   \n",
       "\n",
       "                                             run_name    run_time  accuracy  \\\n",
       "26  gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...  931.951627  0.622162   \n",
       "13  gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...  117.373195  0.623253   \n",
       "62  gpt-eval-gpu-num-8-icl-tasks-lambada-model-2-7...  117.466429  0.622093   \n",
       "56  gpt-eval-gpu-num-16-icl-tasks-lambada-model-2-...   59.242780  0.621904   \n",
       "9   gpt-eval-gpu-num-16-icl-tasks-lambada-model-2-...   59.174347  0.623253   \n",
       "50  gpt-eval-gpu-num-32-icl-tasks-lambada-model-2-...   30.257925  0.622106   \n",
       "5   gpt-eval-gpu-num-32-icl-tasks-lambada-model-2-...   30.006946  0.623253   \n",
       "1   gpt-eval-gpu-num-64-icl-tasks-lambada-model-2-...   15.647013  0.622106   \n",
       "44  gpt-eval-gpu-num-64-icl-tasks-lambada-model-2-...   15.661913  0.622106   \n",
       "\n",
       "   eval_method  \n",
       "26    composer  \n",
       "13    composer  \n",
       "62    composer  \n",
       "56    composer  \n",
       "9     composer  \n",
       "50    composer  \n",
       "5     composer  \n",
       "1     composer  \n",
       "44    composer  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec99b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = zip(*big_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d940d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_models = [(7e10,110.333),\n",
    "(2.02e11,340.168),\n",
    "(3.23e11,544.74),\n",
    "(4.43e11,741.209)]\n",
    "\n",
    "\n",
    "def billions_formatter(x, pos):\n",
    "    return f'{x / 1000000000}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ca1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y)\n",
    "ax.xaxis.set_major_formatter(FuncFormatter(billions_formatter))\n",
    "plt.title(\"LAMBADA eval time on 64 GPUs\")\n",
    "plt.xlabel('Number of Parameters (billions)')\n",
    "plt.ylabel('Run time (seconds)')\n",
    "plt.savefig(f\"fig4.png\", )\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a342dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
