name: convert_to_hf

scheduling:
  priority: medium

compute:
  gpus: 0  # Number of GPUs to use

  ## These configurations are optional
  # cluster: r0z0 # Name of the cluster to use for this run
  # gpu_type: a100_80gb # Type of GPU to use.

integrations:
# Clone and install the llm-foundry repo so we can run scripts from it
- integration_type: git_repo
  git_repo: mosaicml/llm-foundry
  pip_install:  -e .
  ssh_clone: false # Should be true if using a private repo
  git_commit: 68448b2764cf6988c830e4d55796e6e28cdac20e

# cd into the scripts/inference folder and run the MPT conversion script from LLM-foundry
command: |
  cd llm-foundry/scripts/inference
  python convert_composer_to_hf.py \
    --composer_path CLOUD://BUCKET_NAME/support-bot-demo/checkpoints/CHECKPOINT_FOLDER_NAME/latest-rank0.pt.symlink \
    --hf_output_path s3://BUCKET_NAME/support-bot-demo/converted_checkpoints/HF_FOLDER_NAME/ \
    --output_precision bf16 \

image: mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04 # Use the Docker image provided by MosaicML
