name: convert-PyPi-to-stream

compute:
  gpus: 0  # Number of GPUs to use

  ## These configurations are optional
  # cluster: r0z0 # Name of the cluster to use for this run
  # gpu_type: a100_80gb # Type of GPU to use.

integrations:
# Clone the examples repository so that we have access to the code in sec_10k_qa
- integration_type: git_repo
  git_repo: KuuCi/examples
  git_branch: support-bot
  ssh_clone: false # Should be true if using a private repo
  path: /workspace/examples # Tell MCLI what path to clone the repo to

# cd into the chatbot folder
# Install the necessary dependencies
# Run the script to process the raw data files and upload them to the cloud in the correct format
command: |
  cd /workspace/examples/examples/end-to-end-examples/support_chatbot/
  pip install -r requirements.txt
  python scripts/conversion/convert_PyPi_to_stream.py \
    --out_root oci://mosaicml-internal-checkpoints/support-bot-demo/data/PyPi_mds/ \

image: mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04 # Use the Docker image provided by MosaicML