name: mpt-30b-ft
compute:
  gpus: 2
  gpu_type: a100_40gb
image: mosaicml/inference:0.1.16
replicas: 1
command: |
  export PYTHONPATH=/code/llm-foundry:/code/examples:/code
integrations:
- integration_type: git_repo
  git_repo: mosaicml/examples
  git_commit: df65ce9448f2e4c7803f7082930f80c8dc4e8fe1
  ssh_clone: false
- integration_type: git_repo
  git_repo: mosaicml/llm-foundry
  git_commit: 496b50bd588b1a7231fe54b05d70babb3620fc72
  ssh_clone: false
model:
  backend: faster_transformers
  downloader: examples.inference-deployments.mpt.mpt_ft_handler.download_convert
  download_parameters:
    hf_path: mosaicml/mpt-30b
    gpus: 2
    force_conversion: true
  model_handler: examples.inference-deployments.mpt.mpt_ft_handler.MPTFTModelHandler
  model_parameters:
    model_name_or_path: mosaicml/mpt-30b
    ft_lib_path: /code/FasterTransformer/build/lib/libth_transformer.so
    gpus: 2
